{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.2 64-bit"
  },
  "interpreter": {
   "hash": "f3aa6331c07ee25bacc791f93f707d5a9245b8fc1ed968ce9ad3ec4728621a3f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# SeFa Implementation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Fetch Codebase and Models"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.join(os.getcwd(), 'genforce'))\n",
    "if os.path.exists('/content'):\n",
    "    os.chdir('/content')\n",
    "    CODE_DIR = 'SeFaInvert'\n",
    "    if not os.path.exists(CODE_DIR):\n",
    "        !git clone https://github.com/MrLishu/GANInvert.git $CODE_DIR\n",
    "    os.chdir(f'./{CODE_DIR}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('genforce')\n",
    "MODEL_DIR = os.path.join('models', 'pretrain')\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "!wget https://mycuhk-my.sharepoint.com/:u:/g/personal/1155082926_link_cuhk_edu_hk/EXqix_JIEgtLl1FXI4uCkr8B5GPaiJyiLXL6cFbdcIKqEA?e=WYesel\\&download\\=1 -O $MODEL_DIR/styleganinv_ffhq256_encoder.pth  --quiet\n",
    "!wget https://mycuhk-my.sharepoint.com/:u:/g/personal/1155082926_link_cuhk_edu_hk/EbuzMQ3ZLl1AqvKJzeeBq7IBoQD-C1LfMIC8USlmOMPt3Q?e=CMXn8W\\&download\\=1 -O $MODEL_DIR/styleganinv_ffhq256_generator.pth  --quiet\n",
    "!wget https://mycuhk-my.sharepoint.com/:u:/g/personal/1155082926_link_cuhk_edu_hk/EQJUz9DInbxEnp0aomkGGzAB5b3ZZbtsOA-TXct9E4ONqA?e=smtO0T\\&download\\=1 -O $MODEL_DIR/vgg16.pth  --quiet\n",
    "os.chdir('..')"
   ]
  },
  {
   "source": [
    "## Import StyleGAN and GAN Inverter"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'dlib'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-95fe91b7a215>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mgenforce\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minverter\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mStyleGANInverter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgenforce\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mface_landmark_detector\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mFaceLandmarkDetector\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mIMAGE_SIZE\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m64\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\MrLishu\\OneDrive - tongji.edu.cn\\Documents\\GitHub\\GANInvert\\genforce\\models\\face_landmark_detector.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mdlib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndimage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'dlib'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from genforce.utils.inverter import StyleGANInverter\n",
    "from genforce.models.face_landmark_detector import FaceLandmarkDetector\n",
    "\n",
    "inverter = StyleGANInverter('styleganinv_ffhq256', learning_rate=0.01, iteration=100,\n",
    "                            reconstruction_loss_weight=1.0, perceptual_loss_weight=5e-5, regularization_loss_weight=0)\n",
    "generator = inverter.G\n",
    "resolution = inverter.G.resolution\n",
    "\n",
    "def align(image_name):\n",
    "    face_landmark_detector = FaceLandmarkDetector(resolution)\n",
    "    face_infos = face_landmark_detector.detect(os.path.join('images', image_name))[0]\n",
    "    image = face_landmark_detector.align(face_infos)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_image_name = 'emma.png'\n",
    "source_image = align(source_image_name)\n",
    "source_image_code = inverter.easy_invert(source_image, 1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_image_name = '000001.png'\n",
    "target_image = align(target_image_name)\n",
    "target_image_code = inverter.easy_invert(target_image, 1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_low = 6 #@param {type:\"slider\", min:0, max:13, step:1}\n",
    "layer_high = 13 #@param {type:\"slider\", min:0, max:13, step:1}\n",
    "semantic = 4 #@param {type:\"slider\", min:1, max:10, step:1}\n",
    "\n",
    "layers = list(range(layer_low, layer_high + 1))\n",
    "\n",
    "weights = []\n",
    "for layer in layers:\n",
    "    weights.append(generator.net.synthesis.__getattr__(f'layer{layer}').epilogue.style_mod.dense.fc.weight.T.cpu().detach().numpy())\n",
    "weight = np.concatenate(weights, axis=1).astype(np.float32)\n",
    "weight = weight / np.linalg.norm(weight, axis=0, keepdims=True)\n",
    "eigen_values, eigen_vectors = np.linalg.eig(weight.dot(weight.T))\n",
    "boundaries = eigen_vectors.T\n",
    "boundary = boundaries[semantic]\n",
    "\n",
    "sematic_up = 4 #@param {type:\"slider\", min:0, max:5, step:0.1}\n",
    "sematic_down = -4 #@param {type:\"slider\", min:-10, max:0, step:0.1}\n",
    "steps = 7 #@param {type:\"slider\", min:2, max:12, step:1}\n",
    "\n",
    "new_codes = source_image_code.repeat(steps, axis=0).reshape(steps, generator.net.num_layers, -1)\n",
    "new_codes[:, layers, :] += boundary.reshape(1, 1, -1) * np.linspace(sematic_down, sematic_up, steps, dtype=np.float32).reshape(-1, 1, 1)\n",
    "new_images = generator.easy_synthesize(new_codes, latent_space_type='wp')['image']\n",
    "\n",
    "plt.figure(figsize=(19.2, 10.8))\n",
    "plt.axis(\"off\")\n",
    "plt.title(f\"Images on {layers}\")\n",
    "plt.imshow(np.concatenate(new_images, axis=1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step = 7\n",
    "\n",
    "source_image_name = 'zky.jpg'\n",
    "target_image_name = 'qd.jpg'\n",
    "\n",
    "source_image = align(source_image_name)\n",
    "target_image = align(target_image_name)\n",
    "\n",
    "source_image_code = inverter.easy_invert(source_image, 1)[0]\n",
    "target_image_code = inverter.easy_invert(target_image, 1)[0]\n",
    "\n",
    "linspace = np.linspace(0, 1, step).reshape(-1, 1, 1).astype(np.float32)\n",
    "inter_codes = (1 - linspace) * source_image_code + linspace * target_image_code\n",
    "inter_images = generator.easy_synthesize(inter_codes, latent_space_type='wp')['image']\n",
    "\n",
    "plt.figure(figsize=(19.2, 10.8))\n",
    "plt.axis(\"off\")\n",
    "plt.title(f\"Interpolated images between {source_image_name.split('.')[0]} and {target_image_name.split('.')[0]}\")\n",
    "plt.imshow(np.concatenate(inter_images, axis=1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "\n",
    "def addManipulateImages(writer, layers, sematic, sematic_limits, duration=8):\n",
    "  weights = []\n",
    "  for layer in layers:\n",
    "    weights.append(generator.net.synthesis.__getattr__(f'layer{layer}').epilogue.style_mod.dense.fc.weight.T.cpu().detach().numpy())\n",
    "  weight = np.concatenate(weights, axis=1).astype(np.float32)\n",
    "  weight = weight / np.linalg.norm(weight, axis=0, keepdims=True)\n",
    "  eigen_values, eigen_vectors = np.linalg.eig(weight.dot(weight.T))\n",
    "  boundaries = eigen_vectors.T\n",
    "  boundary = boundaries[semantic]\n",
    "\n",
    "  steps = int(duration / 2 * 24)\n",
    "  linspace = np.r_[np.linspace(0, sematic_limits, steps, dtype=np.float32).reshape(-1, 1, 1),\n",
    "             np.linspace(sematic_limits, 0, steps, dtype=np.float32).reshape(-1, 1, 1)]\n",
    "\n",
    "  new_codes = source_image_code.repeat(steps * 2, axis=0).reshape(steps * 2, generator.net.num_layers, -1)\n",
    "  new_codes[:, layers, :] += boundary.reshape(1, 1, -1) * linspace\n",
    "  new_images = generator.easy_synthesize(new_codes, latent_space_type='wp')['image']\n",
    "\n",
    "  for i in range(steps * 2):\n",
    "    b, g, r = new_images[i].transpose(2, 0, 1)\n",
    "    image = np.array([r, g, b]).transpose(1, 2, 0)\n",
    "    writer.write(image)\n",
    "\n",
    "def addInterpolateImages(writer, duration=8):\n",
    "  steps = int(duration / 2 * 24)\n",
    "\n",
    "  linspace = np.r_[np.linspace(0, 1, steps, dtype=np.float32).reshape(-1, 1, 1),\n",
    "             np.linspace(1, 0, steps, dtype=np.float32).reshape(-1, 1, 1)]\n",
    "  inter_codes = (1 - linspace) * source_image_code + linspace * target_image_code\n",
    "  inter_images = generator.easy_synthesize(inter_codes, latent_space_type='wp')['image']\n",
    "\n",
    "  for i in range(steps * 2):\n",
    "    b, g, r = inter_images[i].transpose(2, 0, 1)\n",
    "    image = np.array([r, g, b]).transpose(1, 2, 0)\n",
    "    writer.write(image)\n",
    "\n",
    "\n",
    "videowriter = cv.VideoWriter(rf'{source_image_name.split(\".\")[0]}.mp4', cv.VideoWriter_fourcc(*'XVID'), 24, (resolution, resolution))\n",
    "addManipulateImages(videowriter, [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], sematic=1, sematic_limits=2)\n",
    "addManipulateImages(videowriter, [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], sematic=1, sematic_limits=-4)\n",
    "addManipulateImages(videowriter, [2, 3, 4], sematic=1, sematic_limits=4)\n",
    "addManipulateImages(videowriter, [2, 3, 4], sematic=1, sematic_limits=-4)\n",
    "addInterpolateImages(videowriter)\n",
    "videowriter.release()"
   ]
  }
 ]
}